{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch import optim, nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from numpy.random import permutation\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN architecture\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(\n",
    "            in_channels=1, \n",
    "            out_channels=32,\n",
    "            kernel_size=(3, 3, 3), \n",
    "            stride=(1, 1, 1),\n",
    "            padding=(0, 0, 0)\n",
    "        )\n",
    "        self.conv1_bn = nn.BatchNorm3d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv3d(\n",
    "            in_channels=32,\n",
    "            out_channels=64, \n",
    "            kernel_size=(1, 3, 3), \n",
    "            stride=(1, 1, 1)\n",
    "        )\n",
    "        self.conv2_bn = nn.BatchNorm3d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(\n",
    "            in_channels=64, \n",
    "            out_channels=64, \n",
    "            kernel_size=(1, 3, 3), \n",
    "            stride=(1, 1, 1)\n",
    "        )\n",
    "        self.conv3_bn = nn.BatchNorm3d(64)\n",
    "        \n",
    "        # self.fc1 = nn.Linear(64*11*11, 500)\n",
    "        self.fc1 = nn.Linear(64*24*24, 500)\n",
    "        self.fc2 = nn.Linear(500, 2500)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = x.view(-1, 1, 3, 102, 102)\n",
    "        \n",
    "        # x = self.conv1_bn(self.conv1(x))\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(F.max_pool3d(x, kernel_size=(1, 2, 2)))\n",
    "        \n",
    "        # x = self.conv2_bn(self.conv2(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(F.max_pool3d(x, kernel_size=(1, 2, 2)))\n",
    "        \n",
    "        # x = self.conv3_bn(self.conv3(x))\n",
    "        # x = F.relu(F.max_pool3d(x, kernel_size=(1, 2, 2)))\n",
    "        \n",
    "        # x = x.view(-1, 64*11*11)\n",
    "        x = x.view(-1, 64*24*24)\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "def evaluate_model(model, loss_fn, val_data_loader):\n",
    "    losses = []\n",
    "    rmse_values = []\n",
    "    \n",
    "    with torch.no_grad():  # There is no need to calculate gradients for the validation set\n",
    "        for b_x, b_y in val_data_loader:\n",
    "            model.eval()\n",
    "            \n",
    "            # Run batch on GPU, if possible\n",
    "            b_x = b_x.to(device)\n",
    "            b_y = b_y.to(device)\n",
    "            \n",
    "            # Compute predictions and losses\n",
    "            preds = model(b_x)\n",
    "            \n",
    "            temp = preds.cpu().detach().numpy() - b_y.cpu().detach().numpy()\n",
    "            temp = temp**2\n",
    "            \n",
    "            rmse = np.sqrt(temp.mean())\n",
    "            rmse_values.append(rmse)\n",
    "            \n",
    "            loss = loss_fn(preds, b_y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        val_avg_loss = sum(losses)/len(losses)    \n",
    "    \n",
    "    return val_avg_loss, np.array(rmse_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDVI(ds):\n",
    "    ndvi = (ds.B8A_20m - ds.B04_20m) / (ds.B8A_20m + ds.B04_20m)\n",
    "    return ndvi.values\n",
    "        \n",
    "def measure_cloudfrees(ds):\n",
    "    W_valid = masking_valid(ds)\n",
    "    cloud_fr = W_valid.isin([1]).sum(dim=['x', 'y']) / ds.SCL_20m.isel(time=0).count(dim = ['x', 'y'])\n",
    "    return cloud_fr.values\n",
    "     \n",
    "def masking_valid(ds):\n",
    "    W_valid = ds.SCL_20m.where(((ds.SCL_20m>=4) & (ds.SCL_20m<=5)),0)\n",
    "    W_valid=W_valid.where(W_valid==0,1)\n",
    "    return W_valid\n",
    "\n",
    "def find_indices(cloudfrees, n):\n",
    "    cloudfrees2 = cloudfrees.copy()\n",
    "    if n == 0:\n",
    "        id1 = 1+np.argmax(cloudfrees2[1:])\n",
    "        cloudfrees2[id1] = -1\n",
    "        id2 = 1+np.argmax(cloudfrees2[1:])\n",
    "        return [id1, id2]\n",
    "    elif n == len(cloudfrees2)-1:\n",
    "        id1 = np.argmax(cloudfrees2[:len(cloudfrees2)-1])\n",
    "        cloudfrees2[id1] = -1\n",
    "        id2 = np.argmax(cloudfrees2[:len(cloudfrees2)-1])\n",
    "        return [id1, id2]\n",
    "    else:\n",
    "        id1 = np.argmax(cloudfrees2[:n])\n",
    "        id2 = n+np.argmax(cloudfrees2[n+1:])\n",
    "        return [id1, id2]\n",
    "\n",
    "def create_training_set(imgs, indices, mask_size, depth = 4):\n",
    "    \"\"\" imgs is a list of list where each list contains N numpy arrays \"\"\"\n",
    "    mask_size_x = mask_size[0] \n",
    "    mask_size_y = mask_size[1]\n",
    "    mask = np.zeros((mask_size_x, mask_size_y))\n",
    "    training_set = []\n",
    "    targets = []\n",
    "    for j, img_batch in enumerate(imgs): # for each list with np arrays in imgs\n",
    "        for i in range(len(img_batch) - 3 + 1):\n",
    "            \n",
    "            inds1 = indices[j][i][0]\n",
    "            inds2 = indices[j][i][1]\n",
    "                        \n",
    "            if inds1 < i and inds2 < i:\n",
    "                mat = img_batch[inds1][np.newaxis,...]\n",
    "                mat = np.vstack([ mat, img_batch[inds2][np.newaxis,...] ])\n",
    "                mat = np.vstack([ mat, img_batch[i][np.newaxis,...] ])\n",
    "                \n",
    "            elif inds1 > i and inds2 > i:\n",
    "                \n",
    "                mat = img_batch[i][np.newaxis,...]\n",
    "                #print(inds1, len(img_batch))\n",
    "                mat = np.vstack([ mat, img_batch[inds1][np.newaxis,...] ])\n",
    "                mat = np.vstack([ mat, img_batch[inds2][np.newaxis,...] ])\n",
    "            else:\n",
    "                mat = img_batch[inds1][np.newaxis,...]\n",
    "                mat = np.vstack([ mat, img_batch[i][np.newaxis,...] ])\n",
    "                mat = np.vstack([ mat, img_batch[inds2][np.newaxis,...] ])\n",
    "                            \n",
    "            for k in range(3): # go through the stacked arrays\n",
    "                for l in range(26,74,10): \n",
    "                    for m in range(26,74,10):\n",
    "                        temp = mat.copy()\n",
    "                       \n",
    "                        target = temp[k, l:l + mask_size_y, m:m + mask_size_x].flatten()\n",
    "                        targets.append(target)\n",
    "                        temp[k, l:l + mask_size_y, m:m + mask_size_x] = mask.copy()\n",
    "                        temp = temp[:, l - 26:l + mask_size_y + 26, m-26:m+mask_size_x + 26]\n",
    "                        training_set.append([temp])\n",
    "                        #print(temp.shape)\n",
    "                        \n",
    "    print('--- The training set consists of ' + str(len(training_set)) + ' images ---')\n",
    "    return training_set, targets\n",
    "\n",
    "\n",
    "def get_inputs_targets(data):\n",
    "    img_ls = []\n",
    "    imgs = []\n",
    "    indices = []\n",
    "    img_batch = NDVI(data)\n",
    "    \n",
    "    cloudfrees = measure_cloudfrees(data)\n",
    "    ind_list = []\n",
    "    for i in range(img_batch.shape[0]):\n",
    "        img = img_batch[i,:,:]\n",
    "        inds = find_indices(cloudfrees, i)\n",
    "        imgs += [img]\n",
    "        ind_list += [inds]\n",
    "    \n",
    "    indices += [ind_list]\n",
    "    img_ls.append(imgs)\n",
    "    \n",
    "    training_data, targets = create_training_set(img_ls, indices, (50,50), 5)\n",
    "    \n",
    "    return training_data, targets\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_targets(data):\n",
    "    img_ls = []\n",
    "    imgs = []\n",
    "    indices = []\n",
    "    img_batch = NDVI(data)\n",
    "    \n",
    "    cloudfrees = measure_cloudfrees(data)\n",
    "    ind_list = []\n",
    "    for i in range(img_batch.shape[0]):\n",
    "        img = img_batch[i,:,:]\n",
    "        inds = find_indices(cloudfrees, i)\n",
    "        imgs += [img]\n",
    "        ind_list += [inds]\n",
    "    \n",
    "    indices += [ind_list]\n",
    "    img_ls.append(imgs)\n",
    "    \n",
    "    training_data, targets = create_training_set(img_ls, indices, (50,50), 5)\n",
    "    \n",
    "    return training_data, targets\n",
    "\n",
    "root_path = 'febhack2020/datasets/training/checked'\n",
    "dataset = get_dataset(root_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "2500\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = dataset[0][0]\n",
    "\n",
    "for i, temp_date in enumerate(data.time.values):\n",
    "    array = data.B05_20m.isel(time=i).values\n",
    "    print(np.sum(array==0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 1275 images ---\n",
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 1125 images ---\n",
      "Batch: 0\n",
      "Batch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.04764\n",
      "Validation loss: 0.01016\n",
      "RMSE: 0.10078\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01109\n",
      "Validation loss: 0.01959\n",
      "RMSE: 0.13998\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01345\n",
      "Validation loss: 0.01042\n",
      "RMSE: 0.10206\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.00902\n",
      "Validation loss: 0.01411\n",
      "RMSE: 0.11878\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01004\n",
      "Validation loss: 0.01261\n",
      "RMSE: 0.11230\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.00913\n",
      "Validation loss: 0.01087\n",
      "RMSE: 0.10426\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01007\n",
      "Validation loss: 0.00845\n",
      "RMSE: 0.09191\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.00893\n",
      "Validation loss: 0.00728\n",
      "RMSE: 0.08533\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01030\n",
      "Validation loss: 0.01096\n",
      "RMSE: 0.10470\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.00908\n",
      "Validation loss: 0.01095\n",
      "RMSE: 0.10463\n",
      "--- The training set consists of 1050 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 1125 images ---\n",
      "Batch: 0\n",
      "Batch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.02537\n",
      "Validation loss: 0.01196\n",
      "RMSE: 0.10937\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.02240\n",
      "Validation loss: 0.01673\n",
      "RMSE: 0.12934\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.02106\n",
      "Validation loss: 0.01381\n",
      "RMSE: 0.11753\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.02081\n",
      "Validation loss: 0.01544\n",
      "RMSE: 0.12425\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.02037\n",
      "Validation loss: 0.01282\n",
      "RMSE: 0.11322\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.02034\n",
      "Validation loss: 0.02296\n",
      "RMSE: 0.15152\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.02000\n",
      "Validation loss: 0.01203\n",
      "RMSE: 0.10968\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.02144\n",
      "Validation loss: 0.01300\n",
      "RMSE: 0.11400\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01985\n",
      "Validation loss: 0.01294\n",
      "RMSE: 0.11376\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.02009\n",
      "Validation loss: 0.01292\n",
      "RMSE: 0.11365\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 1200 images ---\n",
      "--- The training set consists of 1125 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "Batch: 0\n",
      "Batch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02587\n",
      "Validation loss: 0.01106\n",
      "RMSE: 0.10515\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02390\n",
      "Validation loss: 0.01224\n",
      "RMSE: 0.11065\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02335\n",
      "Validation loss: 0.01147\n",
      "RMSE: 0.10709\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02483\n",
      "Validation loss: 0.01319\n",
      "RMSE: 0.11484\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02326\n",
      "Validation loss: 0.01225\n",
      "RMSE: 0.11067\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02324\n",
      "Validation loss: 0.01166\n",
      "RMSE: 0.10800\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02319\n",
      "Validation loss: 0.01337\n",
      "RMSE: 0.11561\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02261\n",
      "Validation loss: 0.01124\n",
      "RMSE: 0.10604\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02276\n",
      "Validation loss: 0.01100\n",
      "RMSE: 0.10490\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02269\n",
      "Validation loss: 0.01168\n",
      "RMSE: 0.10809\n",
      "--- The training set consists of 975 images ---\n",
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 1200 images ---\n",
      "Batch: 0\n",
      "Batch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02813\n",
      "Validation loss: 0.00466\n",
      "RMSE: 0.06824\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02633\n",
      "Validation loss: 0.00369\n",
      "RMSE: 0.06075\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02638\n",
      "Validation loss: 0.00421\n",
      "RMSE: 0.06490\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02533\n",
      "Validation loss: 0.00734\n",
      "RMSE: 0.08569\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02704\n",
      "Validation loss: 0.00405\n",
      "RMSE: 0.06365\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02573\n",
      "Validation loss: 0.00402\n",
      "RMSE: 0.06343\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02570\n",
      "Validation loss: 0.00511\n",
      "RMSE: 0.07149\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02528\n",
      "Validation loss: 0.00497\n",
      "RMSE: 0.07048\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02685\n",
      "Validation loss: 0.00402\n",
      "RMSE: 0.06340\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.02494\n",
      "Validation loss: 0.00413\n",
      "RMSE: 0.06427\n",
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "Batch: 0\n",
      "Batch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Training loss: 0.01655\n",
      "Validation loss: 0.01129\n",
      "RMSE: 0.10627\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Training loss: 0.01524\n",
      "Validation loss: 0.01131\n",
      "RMSE: 0.10633\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Training loss: 0.01518\n",
      "Validation loss: 0.01106\n",
      "RMSE: 0.10515\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Training loss: 0.01479\n",
      "Validation loss: 0.01168\n",
      "RMSE: 0.10806\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Training loss: 0.01473\n",
      "Validation loss: 0.01071\n",
      "RMSE: 0.10350\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Training loss: 0.01470\n",
      "Validation loss: 0.01135\n",
      "RMSE: 0.10654\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Training loss: 0.01451\n",
      "Validation loss: 0.01032\n",
      "RMSE: 0.10160\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Training loss: 0.01453\n",
      "Validation loss: 0.01046\n",
      "RMSE: 0.10227\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Training loss: 0.01466\n",
      "Validation loss: 0.01034\n",
      "RMSE: 0.10167\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Training loss: 0.01456\n",
      "Validation loss: 0.01043\n",
      "RMSE: 0.10214\n",
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 1125 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 1200 images ---\n",
      "Batch: 0\n",
      "Batch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01764\n",
      "Validation loss: 0.01799\n",
      "RMSE: 0.13412\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01684\n",
      "Validation loss: 0.01368\n",
      "RMSE: 0.11696\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01650\n",
      "Validation loss: 0.01403\n",
      "RMSE: 0.11845\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01652\n",
      "Validation loss: 0.01327\n",
      "RMSE: 0.11519\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01656\n",
      "Validation loss: 0.01413\n",
      "RMSE: 0.11887\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01651\n",
      "Validation loss: 0.01359\n",
      "RMSE: 0.11659\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01651\n",
      "Validation loss: 0.01392\n",
      "RMSE: 0.11799\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01638\n",
      "Validation loss: 0.01380\n",
      "RMSE: 0.11749\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01628\n",
      "Validation loss: 0.01375\n",
      "RMSE: 0.11724\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01642\n",
      "Validation loss: 0.01333\n",
      "RMSE: 0.11544\n",
      "--- The training set consists of 1125 images ---\n",
      "--- The training set consists of 1200 images ---\n",
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 900 images ---\n",
      "Batch: 0\n",
      "Batch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01258\n",
      "Validation loss: 0.01006\n",
      "RMSE: 0.10029\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01175\n",
      "Validation loss: 0.00889\n",
      "RMSE: 0.09431\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01164\n",
      "Validation loss: 0.01024\n",
      "RMSE: 0.10119\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01153\n",
      "Validation loss: 0.01025\n",
      "RMSE: 0.10124\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01150\n",
      "Validation loss: 0.00951\n",
      "RMSE: 0.09749\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01167\n",
      "Validation loss: 0.01044\n",
      "RMSE: 0.10216\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01151\n",
      "Validation loss: 0.00980\n",
      "RMSE: 0.09901\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01147\n",
      "Validation loss: 0.00980\n",
      "RMSE: 0.09899\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01150\n",
      "Validation loss: 0.01009\n",
      "RMSE: 0.10047\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01140\n",
      "Validation loss: 0.00968\n",
      "RMSE: 0.09837\n",
      "--- The training set consists of 1125 images ---\n",
      "--- The training set consists of 1200 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 675 images ---\n",
      "Batch: 0\n",
      "Batch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01629\n",
      "Validation loss: 0.00939\n",
      "RMSE: 0.09688\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01549\n",
      "Validation loss: 0.00863\n",
      "RMSE: 0.09290\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01538\n",
      "Validation loss: 0.00902\n",
      "RMSE: 0.09496\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01528\n",
      "Validation loss: 0.00786\n",
      "RMSE: 0.08867\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01573\n",
      "Validation loss: 0.00766\n",
      "RMSE: 0.08753\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01524\n",
      "Validation loss: 0.00781\n",
      "RMSE: 0.08835\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01511\n",
      "Validation loss: 0.00914\n",
      "RMSE: 0.09561\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01539\n",
      "Validation loss: 0.00793\n",
      "RMSE: 0.08902\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01502\n",
      "Validation loss: 0.00816\n",
      "RMSE: 0.09035\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Training loss: 0.01510\n",
      "Validation loss: 0.00825\n",
      "RMSE: 0.09085\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 1125 images ---\n",
      "--- The training set consists of 1125 images ---\n",
      "--- The training set consists of 1125 images ---\n",
      "--- The training set consists of 675 images ---\n",
      "Batch: 0\n",
      "Batch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Batch: 130\n",
      "Training loss: 0.01848\n",
      "Validation loss: 0.02116\n",
      "RMSE: 0.14547\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Batch: 130\n",
      "Training loss: 0.01702\n",
      "Validation loss: 0.01458\n",
      "RMSE: 0.12075\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Batch: 130\n",
      "Training loss: 0.01648\n",
      "Validation loss: 0.01718\n",
      "RMSE: 0.13108\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Batch: 130\n",
      "Training loss: 0.01634\n",
      "Validation loss: 0.01328\n",
      "RMSE: 0.11525\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Batch: 130\n",
      "Training loss: 0.01741\n",
      "Validation loss: 0.01597\n",
      "RMSE: 0.12635\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Batch: 130\n",
      "Training loss: 0.01607\n",
      "Validation loss: 0.01745\n",
      "RMSE: 0.13208\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Batch: 130\n",
      "Training loss: 0.01602\n",
      "Validation loss: 0.01255\n",
      "RMSE: 0.11202\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Batch: 130\n",
      "Training loss: 0.01594\n",
      "Validation loss: 0.01670\n",
      "RMSE: 0.12923\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Batch: 130\n",
      "Training loss: 0.01592\n",
      "Validation loss: 0.01547\n",
      "RMSE: 0.12439\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Batch: 120\n",
      "Batch: 130\n",
      "Training loss: 0.01608\n",
      "Validation loss: 0.01615\n",
      "RMSE: 0.12709\n",
      "--- The training set consists of 675 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "--- The training set consists of 1275 images ---\n",
      "--- The training set consists of 750 images ---\n",
      "Batch: 0\n",
      "Batch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01297\n",
      "Validation loss: 0.01136\n",
      "RMSE: 0.10657\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01278\n",
      "Validation loss: 0.01104\n",
      "RMSE: 0.10505\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01250\n",
      "Validation loss: 0.01163\n",
      "RMSE: 0.10786\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01243\n",
      "Validation loss: 0.01126\n",
      "RMSE: 0.10613\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01246\n",
      "Validation loss: 0.01196\n",
      "RMSE: 0.10934\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01255\n",
      "Validation loss: 0.01201\n",
      "RMSE: 0.10960\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01245\n",
      "Validation loss: 0.01125\n",
      "RMSE: 0.10606\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01236\n",
      "Validation loss: 0.01166\n",
      "RMSE: 0.10797\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01256\n",
      "Validation loss: 0.01170\n",
      "RMSE: 0.10817\n",
      "Batch: 0\n",
      "Batch: 10\n",
      "Batch: 20\n",
      "Batch: 30\n",
      "Batch: 40\n",
      "Batch: 50\n",
      "Batch: 60\n",
      "Batch: 70\n",
      "Batch: 80\n",
      "Batch: 90\n",
      "Batch: 100\n",
      "Batch: 110\n",
      "Training loss: 0.01235\n",
      "Validation loss: 0.01220\n",
      "RMSE: 0.11047\n"
     ]
    }
   ],
   "source": [
    "def get_dataset(root_path):\n",
    "    dataset = []\n",
    "    for subdir, dirs, files in os.walk(root_path):\n",
    "        for file in files:\n",
    "            filepath = subdir + os.sep + file\n",
    "            if 'data1b.pickle' in filepath:\n",
    "                #img_paths.append(filepath)\n",
    "                file = open(filepath, 'rb')\n",
    "                data = pickle.load(file)\n",
    "                file.close()\n",
    "                fname = filepath.split('/')[-2]\n",
    "                dataset.append((data, fname.split('_')[0]))\n",
    "    return dataset\n",
    "\n",
    "root_path = 'febhack2020/datasets/training/checked'\n",
    "dataset = get_dataset(root_path)\n",
    "\n",
    "#################\n",
    "##### TRAIN #####\n",
    "#################\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_network(model, n_epochs, batch_size, loss_fn, optimizer, dataset):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for _ in range(n_epochs):\n",
    "    \n",
    "        inds = np.random.choice(len(dataset), 5, replace =False)\n",
    "        inputs = []\n",
    "        targets = []\n",
    "        for j in inds:\n",
    "            d, date_to_remove = dataset[j]\n",
    "            \n",
    "            temp_indices = []\n",
    "            for i, temp_date in enumerate(d.time.values):\n",
    "                array = d.B05_20m.isel(time=i).values\n",
    "                if np.sum(array==0) > 0:\n",
    "                    temp_indices.append(i)\n",
    "            \n",
    "            #for i in temp_indices:\n",
    "            d = d.where(~d.time.isin(d.time[temp_indices]), drop=True)\n",
    "\n",
    "            temp_inputs, temp_targets = get_inputs_targets(d)\n",
    "            inputs.extend(temp_inputs)\n",
    "            targets.extend(temp_targets)\n",
    "\n",
    "        i_training = int(0.9 * len(inputs))\n",
    "\n",
    "        train_x = inputs[:i_training]\n",
    "        val_x = inputs[i_training:]\n",
    "\n",
    "        train_y = targets[:i_training]\n",
    "        val_y = targets[i_training:]\n",
    "\n",
    "        tensor_train_x = torch.Tensor(train_x)\n",
    "        tensor_train_y = torch.Tensor(train_y)\n",
    "\n",
    "        tensor_val_x = torch.Tensor(val_x)\n",
    "        tensor_val_y = torch.Tensor(val_y)\n",
    "\n",
    "        train_dataset = data.TensorDataset(tensor_train_x, tensor_train_y)\n",
    "        val_dataset = data.TensorDataset(tensor_val_x, tensor_val_y)\n",
    "\n",
    "        train_data_loader = data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "        val_data_loader = data.DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        for i_epoch in range(n_epochs):\n",
    "            # print('--- Epoch: {} ---'.format(i_epoch))\n",
    "            losses = []\n",
    "            model.train()\n",
    "\n",
    "            for i_batch, (b_x, b_y) in enumerate(train_data_loader):\n",
    "                if i_batch % 10 == 0: print('Batch: {}'.format(i_batch))\n",
    "\n",
    "                # Run batch on GPU, if possible\n",
    "                b_x = b_x.to(device)\n",
    "                b_y = b_y.to(device)\n",
    "\n",
    "                # Compute predictions and losses\n",
    "                preds = model(b_x)\n",
    "                loss = loss_fn(preds, b_y)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "                # Backpropagate\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            # Compute loss in the entire training set\n",
    "            train_avg_loss = sum(losses)/len(losses)\n",
    "\n",
    "            # Compute loss in the entire validation set\n",
    "            val_avg_loss, rmse_values = evaluate_model(model, loss_fn, val_data_loader)\n",
    "\n",
    "            print('Training loss: %.5f' % train_avg_loss)\n",
    "            print('Validation loss: %.5f' % val_avg_loss)\n",
    "            print('RMSE: %.5f' % np.sqrt(np.mean(rmse_values**2)))\n",
    "\n",
    "            train_losses.append(train_avg_loss)\n",
    "            val_losses.append(val_avg_loss)\n",
    "    \n",
    "    return train_losses, val_losses\n",
    "        \n",
    "model = CNNClassifier()\n",
    "model.to(device);\n",
    "\n",
    "n_epochs = 10\n",
    "batch_size = 32\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.005)\n",
    "    \n",
    "train_losses, val_losses = \\\n",
    "    train_network(model, n_epochs, batch_size, loss_fn, optimizer, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_gdf_data(filepath):\n",
    "    # Load the data provided (input data to your model)\n",
    "    data1a = pd.read_csv(filepath + \"/data1a.csv\")\n",
    "    data1b = pickle.load(open(filepath + \"/data1b.pickle\", \"rb\"))\n",
    "    # Get the index n where the missing data is located\n",
    "    filename = filepath.split(\"/\")[-1]\n",
    "    datestr = filename.split(\"_\")[0]\n",
    "    #dt = pd.to_datetime(datestr)\n",
    "    #first_date = \"%04d-%02d-01\"%(dt.year,dt.month)\n",
    "    #last_date = \"%04d-%02d-01\"%(dt.year,dt.month+1)\n",
    "    n = np.argwhere(data1b.time.dt.strftime(\"%Y-%m-%d\").values == datestr)[0][0]\n",
    "    # Read the geojson polygon\n",
    "    gdf = gpd.read_file(filepath + \"/\" + filename + \".geojson\")\n",
    "    return data1a, data1b, n, gdf\n",
    "\n",
    "def read_solutions(filepath, filename=\"answer\"):    \n",
    "    #Read the SOLUTIONS\n",
    "    #Task 1a\n",
    "    with open(filepath + \"/\" + filename + \"1a.txt\", \"r\") as f:\n",
    "        solution1a = f.read()\n",
    "    #Task 1b\n",
    "    with open(filepath + \"/\" + filename + \"1b.pickle\", \"rb\") as f:\n",
    "        solution1b = pickle.load(f)\n",
    "    return solution1a, solution1b\n",
    "\n",
    "def NDVI(ds):\n",
    "    ndvi = (ds.B8A_20m - ds.B04_20m) / (ds.B8A_20m + ds.B04_20m)\n",
    "    return ndvi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22607055\n",
      "0.18518923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2889991\n",
      "0.1763036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2248437\n",
      "0.16531423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20471868\n",
      "0.15551734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19652748\n",
      "0.28000307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21177359\n",
      "0.18695785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21319996\n",
      "0.21158709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23098147\n",
      "0.22278556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23377322\n",
      "0.2711067\n",
      "0.18914445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21261805\n",
      "0.26357207\n",
      "0.14943562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25268906\n",
      "0.13941431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20394224\n",
      "0.28860953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20257066\n",
      "0.20496213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.18929619\n",
      "0.13452229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20615971\n",
      "0.15275872\n",
      "0.20630826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16569516\n",
      "0.2041693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26933527\n",
      "0.1795914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23125863\n",
      "0.13803773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1910797\n",
      "0.25398287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22543128\n",
      "0.28353813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21944472\n",
      "0.31310585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16448735\n",
      "0.24457875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29175636\n",
      "0.17080908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25495532\n",
      "0.21301319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19514224\n",
      "0.18224451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16496566\n",
      "0.22467747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17577462\n",
      "0.25656232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1847682\n",
      "0.17435226\n",
      "0.18850636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19076437\n",
      "0.24990338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20146598\n",
      "0.19240625\n",
      "0.2128602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24785507\n",
      "0.21037875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1841787\n",
      "0.25145677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2000626\n",
      "0.14322914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22448702\n",
      "0.2222974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26119897\n",
      "0.17380653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1612745\n",
      "0.21131389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16285124\n",
      "0.16476144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23782463\n",
      "0.23344591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15868251\n",
      "0.23513153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16143897\n",
      "0.21993521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16820373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16051403\n",
      "0.22158891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26633292\n",
      "0.21860506\n",
      "0.22661142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20491344\n",
      "0.19968253\n",
      "0.23331259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24909243\n",
      "0.22651252\n",
      "0.19164136\n",
      "0.21307793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "##### VALIDATE #####\n",
    "####################\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from glob import glob\n",
    "\n",
    "files = glob(\"/home/jovyan/febhack2020/datasets/validation/*\")\n",
    "\n",
    "all_rmse = []\n",
    "\n",
    "\n",
    "\n",
    "for i, filepath in enumerate(files):\n",
    "    _, data1b, n, gdf = get_n_gdf_data(filepath)\n",
    "    _, solution1b = read_solutions(filepath)\n",
    "    \n",
    "    temp_indices = []\n",
    "    for j, _ in enumerate(data1b.time.values):\n",
    "        array = data1b.B05_20m.isel(time=j).values\n",
    "        if np.sum(array==0) > 0:\n",
    "            temp_indices.append(j)\n",
    "           \n",
    "    temp_indices.remove(n)\n",
    "    \n",
    "    data1b = data1b.where(~data1b.time.isin(data1b.time[temp_indices]), drop=True)\n",
    "    \n",
    "    for l, _ in enumerate(data1b.time.values):\n",
    "        array = data1b.B05_20m.isel(time=l).values\n",
    "        if np.sum(array==0) > 0:\n",
    "            break    \n",
    "            \n",
    "    cloudfrees = measure_cloudfrees(data1b)\n",
    "    indices = find_indices(cloudfrees, l)\n",
    "    \n",
    "    img_batch = NDVI(data1b)\n",
    "    #missing_data = input_data[n]\n",
    "    #nan_indices = np.argwhere(np.isnan(missing_data))\n",
    "    #corner_indices = nan_indices[0]\n",
    "    \n",
    "    # img_batch = [input_data,input_data[l, :, :]]\n",
    "                 \n",
    "    inds1 = indices[0]\n",
    "    inds2 = indices[1]\n",
    "\n",
    "    helper = 0\n",
    "    if inds1 < l and inds2 < l:\n",
    "        helper = 2\n",
    "        mat = img_batch[inds1][np.newaxis,...]\n",
    "        mat = np.vstack([ mat, img_batch[inds2][np.newaxis,...] ])\n",
    "        mat = np.vstack([ mat, img_batch[l][np.newaxis,...] ])\n",
    "\n",
    "    elif inds1 > l and inds2 > l:\n",
    "\n",
    "        mat = img_batch[l][np.newaxis,...]\n",
    "        #print(inds1, len(img_batch))\n",
    "        mat = np.vstack([ mat, img_batch[inds1][np.newaxis,...] ])\n",
    "        mat = np.vstack([ mat, img_batch[inds2][np.newaxis,...] ])\n",
    "        helper = 0\n",
    "    else:\n",
    "        mat = img_batch[inds1][np.newaxis,...]\n",
    "        mat = np.vstack([ mat, img_batch[l][np.newaxis,...] ])\n",
    "        mat = np.vstack([ mat, img_batch[inds2][np.newaxis,...] ])\n",
    "        helper = 1\n",
    "    \n",
    "    nan_indices = np.argwhere(np.isnan(mat[helper, :, :]))\n",
    "    \n",
    "    network_data = np.nan_to_num(mat)\n",
    "    \n",
    "    # print(nan_indices)\n",
    "    \n",
    "    corner_indices = nan_indices[0]\n",
    "    \n",
    "    if helper == 0:\n",
    "        network_data = img_batch[np.array([l, inds1, inds2]), \n",
    "                              corner_indices[0]-26:corner_indices[0]-26+102, \n",
    "                              corner_indices[1]-26:corner_indices[1]-26+102]\n",
    "        n_missing = 0\n",
    "    elif helper == 2:\n",
    "        network_data = img_batch[np.array([inds1, inds2, l]), \n",
    "                              corner_indices[0]-26:corner_indices[0]-26+102, \n",
    "                              corner_indices[1]-26:corner_indices[1]-26+102]\n",
    "        n_missing = 2\n",
    "    else:\n",
    "        network_data = img_batch[np.array([inds1, l, inds2]), \n",
    "                              corner_indices[0]-26:corner_indices[0]-26+102, \n",
    "                              corner_indices[1]-26:corner_indices[1]-26+102]\n",
    "        n_missing = 1\n",
    "    \n",
    "    target = solution1b.values[~np.isnan(solution1b.values)]\n",
    "    \n",
    "    network_data = np.float32(network_data)\n",
    "    target = np.float32(target)\n",
    "    \n",
    "    # print(network_data.shape)\n",
    "    \n",
    "    #print(network_data)\n",
    "    \n",
    "  \n",
    "    try:\n",
    "        network_data_torch = torch.tensor(np.reshape(network_data, (1, 3, 102, 102))) #.view(-1, 1, 3, 102, 102)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # network_data_torch = network_data_torch.unsqueeze\n",
    "    \n",
    "    # data.TensorDataset(network_data_torch, target)\n",
    "    \n",
    "    # network_data_torch = network_data_torch.unsqueeze(0)\n",
    "    network_data_torch = network_data_torch.to(device)\n",
    "    model.eval()\n",
    "    try:\n",
    "        preds = model(network_data_torch)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        rmse = np.sqrt(  np.mean((preds.cpu().detach().numpy()[0] - target)**2 ))\n",
    "        print(rmse)\n",
    "        \n",
    "    except:\n",
    "        print('Calculatation of RMSE failed.')\n",
    "    \n",
    "    all_rmse.append(rmse)\n",
    "\n",
    "print(np.sqrt(np.mean(np.array(all_rmse)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
